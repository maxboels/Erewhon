# ğŸ“Š Training Output Guide

**Updated:** October 9, 2025

## ğŸ¨ New Improved Training Output

### What Changed:

1. âœ… **Progress bars** with tqdm (visual training progress)
2. âœ… **Better timestamps** (readable format: `2025-10-09 10:15:47` instead of ISO)
3. âœ… **Ratio display** (current/total batches and epochs)
4. âœ… **ETA** (estimated time remaining)
5. âœ… **Tree-style summaries** for better readability

---

## ğŸ“º Example Output

### Startup:
```
================================================================================
ğŸ¤– LEROBOT ACT TRAINER FOR RC CAR
================================================================================

ğŸ“ Data Directory: src/robots/rover/episodes
ğŸ” Scanning for episodes...
   Scanning episodes: 10/88 (11%)
   Scanning episodes: 20/88 (22%)
   ...
âœ… Successfully loaded 84 valid episodes

================================================================================
ğŸš€ STARTING TRAINING
================================================================================
ğŸ“Š Training samples: 9937
ğŸ“Š Validation samples: 2484
ğŸ¯ Total epochs: 30
ğŸ“¦ Batch size: 16
ğŸ’¾ Output directory: outputs/lerobot_act/lerobot_act_20251009_103015
================================================================================
```

### Training Progress (NEW! ğŸ‰):
```
================================================================================
ğŸƒ EPOCH 1/30
================================================================================

Epoch 1/30:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 350/701 [02:15<02:15, 2.60it/s] Loss: 0.4523 (LR: 1.00e-04)
```

**What it shows:**
- `Epoch 1/30` - Current epoch / total epochs
- `50%` - Percentage complete
- `â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ` - Visual progress bar
- `350/701` - Current batch / total batches
- `[02:15<02:15]` - Elapsed time < Remaining time
- `2.60it/s` - Iterations (batches) per second
- `Loss: 0.4523` - Current average loss
- `LR: 1.00e-04` - Current learning rate

### Validation Progress:
```
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 155/155 [00:15<00:00, 10.2it/s] Loss: 0.0561
```

### Epoch Summary (NEW! ğŸ‰):
```
ğŸŒŸ New best model! Val loss: 0.056080

ğŸ“Š Epoch 1/30 Summary:
   â”œâ”€ Train Loss: 1.427284
   â”œâ”€ Val Loss:   0.056080
   â”œâ”€ Best Loss:  0.056080
   â”œâ”€ LR:         5.05e-05
   â””â”€ Time:       5m 17s
```

**Tree-style layout:**
- `â”œâ”€` = intermediate items
- `â””â”€` = last item
- Easy to scan visually

### Completion:
```
================================================================================
ğŸ‰ TRAINING COMPLETED!
================================================================================
ğŸ“Š Best validation loss: 0.045123
â±ï¸  Total training time: 2h 45m 32s
ğŸ“ Models saved in: outputs/lerobot_act/lerobot_act_20251009_103015
================================================================================
```

---

## ğŸ“ CSV Log Format (Updated)

### Batch Metrics (`batch_metrics.csv`):

**Old format:**
```csv
step,epoch,batch_loss,learning_rate,timestamp
0,0,95.94695,0.0001,2025-10-09T10:15:47.602829
```

**New format:**
```csv
step,epoch,batch_loss,learning_rate,timestamp
0,0,95.94695,0.0001,2025-10-09 10:15:47
```

âœ… Much easier to read!

### Epoch Metrics (`epoch_metrics.csv`):

**Old format:**
```csv
epoch,train_loss,val_loss,best_val_loss,learning_rate,epoch_time,total_samples,timestamp
0,1.427,0.056,0.056,5.05e-05,317.65,12421,2025-10-09T10:21:28.149100
```

**New format:**
```csv
epoch,train_loss,val_loss,best_val_loss,learning_rate,epoch_time,total_samples,timestamp
0,1.427,0.056,0.056,5.05e-05,317.65,12421,2025-10-09 10:21:28
```

âœ… Human-readable timestamps!

---

## ğŸ¯ Understanding Your Training Logs

### From Your Recent 2-Epoch Run:

#### Batch Metrics:
```
Step 0:    Loss = 95.95  â† Random initialization
Step 10:   Loss = 6.57   â† 93% drop in 10 steps!
Step 100:  Loss = 2.06   â† 98% drop
Step 500:  Loss = 0.55   â† 99.4% drop
Step 770:  Loss = 0.24   â† Epoch 0 complete
```

#### Epoch Summary:
```
Epoch 0:
  - Train Loss: 1.427 (average)
  - Val Loss: 0.056 (excellent!)
  - Time: 5m 17s
  - LR: 1e-4 â†’ 5e-5 (scheduler reduced)

Epoch 1:
  - Train Loss: 0.175 (8x better!)
  - Val Loss: 0.060 (slight increase, normal)
  - Time: 5m 16s
  - LR: 5e-5 â†’ 1e-6 (too aggressive!)
```

### Key Insights:

1. **Model learns FAST** ğŸš€
   - 99.7% loss reduction in epoch 0
   - Already converging well

2. **Not overfitting** âœ…
   - Val loss (0.056) very close to train loss
   - Good generalization

3. **Learning rate issue** âš ï¸
   - Dropped from 1e-4 to 1e-6 in 2 epochs
   - Too aggressive decay
   - Should tune scheduler

---

## ğŸ“Š Monitoring in tmux

### Your 3-Pane Setup:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LEFT: Training Progress Bar    â”‚ TOP-RIGHT: GPU Monitor          â”‚
â”‚                                 â”‚                                 â”‚
â”‚ Epoch 12/30: 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 456/â”‚ GPU: RTX 3070                   â”‚
â”‚ 701 [03:12<01:45] Loss: 0.123  â”‚ Memory: 4350MB / 8188MB (53%)   â”‚
â”‚                                 â”‚ Utilization: 98%                â”‚
â”‚ Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 155/ â”‚ Temp: 72Â°C                      â”‚
â”‚ 155 Loss: 0.098                 â”‚ Power: 150W                     â”‚
â”‚                                 â”‚                                 â”‚
â”‚ ğŸ“Š Epoch 12/30 Summary:         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    â”œâ”€ Train Loss: 0.123         â”‚ BOTTOM-RIGHT: CSV Logs          â”‚
â”‚    â”œâ”€ Val Loss:   0.098         â”‚                                 â”‚
â”‚    â”œâ”€ Best Loss:  0.095         â”‚ step,epoch,loss,lr,timestamp    â”‚
â”‚    â”œâ”€ LR:         3.21e-05      â”‚ 8400,12,0.123,3.21e-05,10:15:47â”‚
â”‚    â””â”€ Time:       2m 45s        â”‚ 8410,12,0.121,3.21e-05,10:15:51â”‚
â”‚                                 â”‚ 8420,12,0.125,3.21e-05,10:15:55â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What Each Pane Shows:

**LEFT (Training):**
- âœ… Real-time progress bar
- âœ… Current/total batches
- âœ… Time elapsed & remaining
- âœ… Live loss updates
- âœ… Epoch summaries

**TOP-RIGHT (GPU):**
- âœ… GPU name & stats
- âœ… Memory usage %
- âœ… GPU utilization %
- âœ… Temperature
- âœ… Power draw

**BOTTOM-RIGHT (Logs):**
- âœ… CSV being written live
- âœ… Step-by-step metrics
- âœ… Readable timestamps

---

## ğŸ’¡ Pro Tips

### Tip 1: Watch Training Speed
```
2.60it/s = 2.6 batches/second
â†’ 701 batches Ã· 2.6 = ~270 seconds = 4.5 minutes per epoch
```

### Tip 2: Estimate Total Time
```
Progress bar shows: [02:15<02:15]
                     â†‘elapsed â†‘remaining
Total epoch time = 4m 30s
```

### Tip 3: Monitor Loss Curve
Watch the loss in the progress bar:
- Decreasing steadily: âœ… Good
- Fluctuating wildly: âš ï¸ LR might be too high
- Stuck/flat: âš ï¸ LR might be too low or converged

### Tip 4: Check GPU Utilization
- 98%: âœ… Perfect, GPU-bound training
- <50%: âš ï¸ CPU bottleneck (data loading slow)
- Memory near max: âš ï¸ Risk of OOM

---

## ğŸ› Troubleshooting

### Progress Bar Not Showing?
**Problem:** Running in environment without tty
**Solution:** Training still works, just no progress bar. Logs still appear.

### Timestamps Still ISO Format?
**Problem:** Old CSV files from previous runs
**Solution:** New runs will use new format. Old files unchanged.

### Progress Bar Glitchy in tmux?
**Problem:** Terminal size or TERM variable
**Solution:** 
```bash
export TERM=xterm-256color
# Or adjust ncols in tqdm: ncols=80
```

### Want to disable progress bar?
**Solution:**
```bash
# Set environment variable:
export TQDM_DISABLE=1
python training_script.py ...
```

---

## ğŸ‰ Summary

Your new training output includes:

âœ… **Visual progress bars** - See training progress in real-time  
âœ… **Readable timestamps** - `2025-10-09 10:15:47` format  
âœ… **Batch/Epoch ratios** - `350/701 batches`, `12/30 epochs`  
âœ… **ETAs** - Know when training will finish  
âœ… **Tree summaries** - Easy to scan epoch results  
âœ… **Time formatting** - `2h 45m 32s` instead of `9932.5s`  

Much better training experience! ğŸš€
