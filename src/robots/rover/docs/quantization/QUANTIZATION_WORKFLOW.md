# ACT Model Quantization Workflow

## Complete Pipeline: Training â†’ Quantization â†’ Deployment

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    1ï¸âƒ£ TRAIN ACT MODEL                           â”‚
â”‚                                                                 â”‚
â”‚  python official_lerobot_trainer.py \                          â”‚
â”‚      --data_dir src/robots/rover/episodes \                    â”‚
â”‚      --output_dir ./outputs/lerobot_act \                      â”‚
â”‚      --epochs 100 --batch_size 8 --device cuda                 â”‚
â”‚                                                                 â”‚
â”‚  Output: best_model.pth (54 MB, FP32, ~100ms latency)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 2ï¸âƒ£ QUANTIZE MODEL (INT8)                        â”‚
â”‚                                                                 â”‚
â”‚  ./deploy_quantized_model.sh \                                 â”‚
â”‚      outputs/lerobot_act/best_model.pth \                      â”‚
â”‚      src/robots/rover/episodes \                               â”‚
â”‚      pi@raspberrypi                                            â”‚
â”‚                                                                 â”‚
â”‚  Steps:                                                         â”‚
â”‚  â”œâ”€ Dynamic quantization (quick test)                          â”‚
â”‚  â”œâ”€ Static quantization (production)                           â”‚
â”‚  â”œâ”€ Accuracy validation (<2% loss)                             â”‚
â”‚  â”œâ”€ Performance benchmark (3-5x speedup)                       â”‚
â”‚  â”œâ”€ Create deployment package                                  â”‚
â”‚  â””â”€ Transfer to Raspberry Pi                                   â”‚
â”‚                                                                 â”‚
â”‚  Output: model_quantized.pth (14 MB, INT8, ~20-30ms latency)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              3ï¸âƒ£ BENCHMARK ON RASPBERRY PI 5                     â”‚
â”‚                                                                 â”‚
â”‚  ssh pi@raspberrypi                                            â”‚
â”‚  cd ~/act_model                                                â”‚
â”‚                                                                 â”‚
â”‚  python3 lerobot_act_inference_rpi5.py \                       â”‚
â”‚      --checkpoint model.pth \                                  â”‚
â”‚      --benchmark --iterations 1000                             â”‚
â”‚                                                                 â”‚
â”‚  Expected Results:                                              â”‚
â”‚  â”œâ”€ Mean latency: 30-40 ms                                     â”‚
â”‚  â”œâ”€ P95 latency:  <50 ms âœ…                                    â”‚
â”‚  â”œâ”€ Throughput:   25-35 FPS                                    â”‚
â”‚  â””â”€ Control rate: 22-30 Hz capable                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            4ï¸âƒ£ DEPLOY TO RC CAR (AUTONOMOUS CONTROL)             â”‚
â”‚                                                                 â”‚
â”‚  python3 lerobot_act_inference_rpi5.py \                       â”‚
â”‚      --checkpoint model.pth \                                  â”‚
â”‚      --camera_id 0 \                                           â”‚
â”‚      --arduino_port /dev/ttyUSB0 \                             â”‚
â”‚      --control_freq 30                                         â”‚
â”‚                                                                 â”‚
â”‚  Real-time control loop:                                        â”‚
â”‚  â”œâ”€ Capture camera frame (30 FPS)                              â”‚
â”‚  â”œâ”€ Preprocess image (resize, normalize)                       â”‚
â”‚  â”œâ”€ Model inference (~30ms)                                    â”‚
â”‚  â”œâ”€ Action chunking (smooth control)                           â”‚
â”‚  â”œâ”€ Convert to PWM values                                      â”‚
â”‚  â””â”€ Send to Arduino â†’ RC car moves! ğŸš—                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Performance Comparison

### Before Quantization (FP32)

```
Model Size:        54 MB
Inference Time:    ~100 ms (dev machine)
                   ~600 ms (Raspberry Pi) âŒ
Control Rate:      <2 Hz (unusable)
Accuracy:          100% (baseline)
```

### After Quantization (INT8 Static)

```
Model Size:        14 MB â†“ 74%
Inference Time:    ~20 ms (dev machine) â†“ 5x
                   ~40 ms (Raspberry Pi) â†“ 15x âœ…
Control Rate:      25-30 Hz (smooth control)
Accuracy:          98-99% (minimal loss)
```

---

## Quantization Methods Comparison

| Method | Speedup | Size | Accuracy | Setup | Use Case |
|--------|---------|------|----------|-------|----------|
| **Dynamic** | 2-4x | â†“75% | 99%+ | Easy | Quick test |
| **Static** | 3-5x | â†“75% | 98%+ | Medium | Production â­ |
| **Mixed** | 2-3x | â†“50% | 99.5%+ | Medium | Max accuracy |

---

## File Structure

```
Erewhon/
â”œâ”€â”€ deploy_quantized_model.sh              # ğŸ”§ Automated pipeline
â”‚
â”œâ”€â”€ src/policies/ACT/
â”‚   â”œâ”€â”€ official_lerobot_trainer.py       # 1ï¸âƒ£ Training
â”‚   â”œâ”€â”€ quantize_act_model.py             # 2ï¸âƒ£ Quantization tool
â”‚   â”œâ”€â”€ lerobot_act_inference_quantized.py # Testing
â”‚   â”œâ”€â”€ lerobot_act_inference_rpi5.py     # 3ï¸âƒ£ 4ï¸âƒ£ Pi deployment
â”‚   â”‚
â”‚   â”œâ”€â”€ QUANTIZATION_GUIDE.md             # ğŸ“– Complete guide
â”‚   â”œâ”€â”€ QUANTIZATION_SUMMARY.md           # ğŸ“‹ Quick reference
â”‚   â””â”€â”€ QUANTIZATION_WORKFLOW.md          # ğŸ“Š This file
â”‚
â””â”€â”€ outputs/lerobot_act/
    â”œâ”€â”€ best_model.pth                     # Original FP32 model
    â””â”€â”€ quantized/
        â”œâ”€â”€ model_dynamic_quant.pth       # Dynamic INT8
        â”œâ”€â”€ model_static_quant.pth        # Static INT8
        â”œâ”€â”€ model_final.pth               # Production model
        â””â”€â”€ deploy/                        # ğŸ“¦ Pi deployment package
            â”œâ”€â”€ model.pth
            â”œâ”€â”€ lerobot_act_inference_rpi5.py
            â”œâ”€â”€ lerobot/
            â””â”€â”€ README.md
```

---

## Quick Commands Reference

### 1. Train Model
```bash
python src/policies/ACT/official_lerobot_trainer.py \
    --data_dir src/robots/rover/episodes \
    --output_dir ./outputs/lerobot_act \
    --epochs 100 --batch_size 8 --device cuda
```

### 2. Quantize (Automated)
```bash
./deploy_quantized_model.sh \
    outputs/lerobot_act/best_model.pth \
    src/robots/rover/episodes \
    pi@raspberrypi
```

### 3. Quantize (Manual)
```bash
# Dynamic (quick)
python src/policies/ACT/quantize_act_model.py \
    --checkpoint outputs/lerobot_act/best_model.pth \
    --mode dynamic \
    --output outputs/lerobot_act/model_quant.pth \
    --benchmark

# Static (production)
python src/policies/ACT/quantize_act_model.py \
    --checkpoint outputs/lerobot_act/best_model.pth \
    --mode static \
    --calibration_data src/robots/rover/episodes \
    --num_calibration_batches 200 \
    --output outputs/lerobot_act/model_quant.pth \
    --benchmark --compare --test_data src/robots/rover/episodes
```

### 4. Test Locally
```bash
# Benchmark
python src/policies/ACT/lerobot_act_inference_quantized.py \
    --checkpoint outputs/lerobot_act/model_quant.pth \
    --benchmark --num_iterations 1000

# Test image
python src/policies/ACT/lerobot_act_inference_quantized.py \
    --checkpoint outputs/lerobot_act/model_quant.pth \
    --test_image test.jpg
```

### 5. Deploy to Pi
```bash
# Transfer
scp -r outputs/lerobot_act/quantized/deploy/ pi@raspberrypi:~/act_model/

# Install (on Pi)
ssh pi@raspberrypi
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cpu
pip3 install numpy opencv-python pillow pyserial tqdm

# Benchmark (on Pi)
cd ~/act_model
python3 lerobot_act_inference_rpi5.py \
    --checkpoint model.pth \
    --benchmark

# Deploy (on Pi)
python3 lerobot_act_inference_rpi5.py \
    --checkpoint model.pth \
    --camera_id 0 \
    --arduino_port /dev/ttyUSB0 \
    --control_freq 30
```

---

## Raspberry Pi 5 Optimizations

### Hardware Configuration
- **CPU:** 4x Cortex-A76 @ 2.4 GHz
- **RAM:** 8GB LPDDR4X
- **Architecture:** ARM v8-A

### Software Optimizations
```python
# 1. ARM-optimized quantization backend
torch.backends.quantized.engine = 'qnnpack'

# 2. Use all 4 cores
torch.set_num_threads(4)

# 3. Fast preprocessing (cv2 on ARM)
frame = cv2.resize(frame, (640, 360))
frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

# 4. Disable gradients
torch.set_grad_enabled(False)

# 5. Batch normalization fusion
torch.quantization.fuse_modules(model, [['conv', 'bn', 'relu']])
```

### Expected Performance
- **Latency:** 30-45ms (P95 <50ms)
- **Control Rate:** 22-30 Hz
- **Power:** ~11W (vs 13W for FP32)
- **Model Size:** 14MB (fits in memory easily)

---

## Validation Checklist

### Before Deployment
- [ ] Model trained successfully
- [ ] Training loss converged (<0.5)
- [ ] Validation accuracy good
- [ ] Best model checkpoint saved

### Quantization
- [ ] Quantization completed without errors
- [ ] Model size reduced (54MB â†’ 14MB)
- [ ] Accuracy preserved (MSE < 0.01)
- [ ] Latency improved (3-5x faster)

### Raspberry Pi Testing
- [ ] Dependencies installed
- [ ] Model transferred successfully
- [ ] Benchmark shows <50ms P95
- [ ] Camera working
- [ ] Arduino connected

### Autonomous Driving
- [ ] Real-time control at 30Hz
- [ ] Smooth steering and throttle
- [ ] Latency stable
- [ ] No crashes or errors

---

## Troubleshooting

### Issue: Slow inference on Pi (>100ms)

**Check:**
1. QNNPACK enabled: `torch.backends.quantized.engine`
2. Thread count: `torch.get_num_threads()` should be 4
3. Model is quantized: file size should be ~14MB, not 54MB

**Fix:**
```python
import torch.backends.quantized
torch.backends.quantized.engine = 'qnnpack'
torch.set_num_threads(4)
```

### Issue: Poor accuracy after quantization

**Check:**
1. MSE should be < 0.01
2. Max error should be < 0.1
3. Visual predictions should look reasonable

**Fix:**
1. Increase calibration samples: `--num_calibration_batches 500`
2. Use more diverse calibration data
3. Try mixed precision: `--mode mixed`

### Issue: Model won't load on Pi

**Check:**
1. PyTorch version compatible
2. Model file not corrupted
3. LeRobot source included

**Fix:**
```bash
# Reinstall PyTorch
pip3 install torch torchvision --force-reinstall

# Verify model
python3 -c "import torch; m=torch.load('model.pth'); print(m.keys())"
```

---

## Performance Monitoring

### Real-time Latency Tracking
```python
import numpy as np
from collections import deque

latencies = deque(maxlen=1000)

for frame in camera:
    start = time.perf_counter()
    steering, throttle = controller.predict(frame)
    latencies.append((time.perf_counter() - start) * 1000)
    
    if len(latencies) % 100 == 0:
        print(f"Avg: {np.mean(latencies):.1f}ms, "
              f"P95: {np.percentile(latencies, 95):.1f}ms")
```

### CPU/Memory Monitoring (on Pi)
```bash
# CPU usage
top -b -n 1 | grep python

# Memory usage
free -h

# Temperature
vcgencmd measure_temp

# Throttling status
vcgencmd get_throttled
```

---

## Next Steps

1. **Train your model** (if not done)
   ```bash
   python src/policies/ACT/official_lerobot_trainer.py ...
   ```

2. **Run quantization pipeline**
   ```bash
   ./deploy_quantized_model.sh outputs/lerobot_act/best_model.pth ...
   ```

3. **Deploy to Raspberry Pi**
   ```bash
   scp -r deploy/ pi@raspberrypi:~/act_model/
   ```

4. **Test and iterate**
   - Benchmark performance
   - Tune control frequency
   - Monitor stability

5. **Future optimizations**
   - Hailo NPU acceleration (AI HAT+)
   - ONNX export for cross-platform
   - TensorRT for Jetson (if switching platform)

---

**Ready to deploy your quantized ACT model! ğŸš€**

See detailed guides:
- `QUANTIZATION_GUIDE.md` - Complete documentation
- `QUANTIZATION_SUMMARY.md` - Implementation summary
